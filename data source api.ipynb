{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These financial data are generally provided in a format that includes the following information:\n",
    "\n",
    "Date\n",
    "Open Price\n",
    "High Price\n",
    "Low Price\n",
    "Closing Price\n",
    "Volume\n",
    "These data—often referred to as OHLC Chart Data—can be interpreted as Time Series data and are perfect for performing technical analysis. We’ll dive into this format in just a moment but, for now, just realize this is a standard format for historical pricing data within financial markets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# yfinance: \n",
    "For this approach, we need to install the yfinance library as pip install yfinance. This library provides sample tools for working with financial data requests to the Yahoo Finance website. Keep in mind, however, this is not an official API and is subject to rate limiting, periodic breakage, and general quirkiness. Nonetheless, its the defacto Python library for OHLC data and can be used as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "tick = ['NVDA','MSFT','AAC','AACG', 'AACI','AACIW','AADI','AAIC','AAL','AAMC','AAME','AAN','AAOI','AAON','AAP','AAPL','AAQC','AAT','AATC','AAU','AAWW','AB','ABB','ABBV','ABC']\n",
    "for i in tick:\n",
    "    data = yf.Ticker(i).history(period='10y')\n",
    "    data.to_csv(i+\".csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quandl:\n",
    "Quandl offers official APIs to access any public dataset for free. Here we’ll see how to get OHLC data via the official Quandl python library and also via the pandas-datareader. One important note is that the free Quandl OHLC data only goes up to 2018 at the time of this article’s writing. If you need more recent data and don’t want to pay this source isn’t for you.\n",
    "\n",
    "Quandl Python Library\n",
    "To get started with Quadl’s official API we need to install the python library as such: pip install quandl. This will install the official quandl python library and let us make up to 50 daily API requests without registering an account. Let’s get our financial data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install quandl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import quandl\n",
    "import time\n",
    "tick = ['NVDA','MSFT','AAC','AACG', 'AACI','AACIW','AADI','AAIC','AAL','AAMC','AAME','AAN','AAOI','AAON','AAP','AAPL','AAQC','AAT','AATC','AAU','AAWW','AB','ABB','ABBV','ABC']\n",
    "# Get data via Quandl API\n",
    "j=0\n",
    "for i in tick:\n",
    "    j+=1\n",
    "    k=1\n",
    "    if j>2*k+1:\n",
    "        time.sleep(600)\n",
    "        k+=20\n",
    "    data = quandl.get('WIKI/NVDA')\n",
    "    data.to_csv(i+\".csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alpha Vantage:\n",
    "The ** pandas-datareader library ** offers easy access to OHLC data via Alpha Vantage integration. The following code will retrieve historical data for different tickers once again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install alpha_vantage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from alpha_vantage.timeseries import TimeSeries\n",
    "import pandas as pd\n",
    "# Create an API object\n",
    "ts = TimeSeries(key='UNO4CZQHSBZSN71N')\n",
    "# Get daily OHLC data for NVDA\n",
    "data, meta_data = ts.get_daily(symbol=\"NVDA\")\n",
    "data_df = pd.DataFrame(data)\n",
    "data_df.to_csv(\"NVDA.csv\", header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alpha Vantage:\n",
    "#### TIME_SERIES_DAILY_ADJUSTED Premium Trending\n",
    "\n",
    "This API returns raw (as-traded) daily open/high/low/close/volume values, daily adjusted close values, and historical split/dividend events of the global equity specified, covering 20+ years of historical data.\n",
    "\n",
    "\n",
    "API Parameters\n",
    "❚ Required: function\n",
    "\n",
    "The time series of your choice. In this case, function=TIME_SERIES_DAILY_ADJUSTED\n",
    "\n",
    "❚ Required: symbol\n",
    "\n",
    "The name of the equity of your choice. For example: symbol=IBM\n",
    "\n",
    "❚ Optional: outputsize\n",
    "\n",
    "By default, outputsize=compact. Strings compact and full are accepted with the following specifications: compact returns only the latest 100 data points; full returns the full-length time series of 20+ years of historical data. The \"compact\" option is recommended if you would like to reduce the data size of each API call.\n",
    "\n",
    "❚ Optional: datatype\n",
    "\n",
    "By default, datatype=json. Strings json and csv are accepted with the following specifications: json returns the daily time series in JSON format; csv returns the time series as a CSV (comma separated value) file.\n",
    "\n",
    "❚ Required: apikey\n",
    "\n",
    "Your API key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# replace the \"demo\" apikey below with your own key from https://www.alphavantage.co/support/#api-key\n",
    "url = 'https://www.alphavantage.co/query?function=TIME_SERIES_DAILY_ADJUSTED&symbol=IBM&apikey=1NSFEG3NTR9VZZOF'\n",
    "r = requests.get(url)\n",
    "data = r.json()\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zerodha-historical-data-download :\n",
    "This contains code to download historical data for more than 2000 days and intraday data for more than 100 days. Download the framework and customize accordingly.\n",
    "\n",
    "The changes you need to make.\n",
    "\n",
    "Set your working directory where you want your data to be downloaded.\n",
    "\n",
    "Enter your API key.\n",
    "\n",
    "Enter youy API secret.\n",
    "\n",
    "Generate request_token.\n",
    "\n",
    "Set the Access token.\n",
    "\n",
    "In the 'tickers' variable write all the stock names you want(write the names exactly as in zerodha app).\n",
    "\n",
    "in the fetchOHLC func, enter the number of days.\n",
    "\n",
    "Note: If you want F&O data, change the instruments('NSE') to instruments('NFO')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install kiteconnect --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kiteconnect import KiteConnect, KiteTicker\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "\n",
    "\n",
    "\n",
    "api_key = 'your_api_key'\n",
    "api_secret = 'your_api_secret'\n",
    "\n",
    "kite = KiteConnect(api_key)\n",
    "url = kite.login_url()\n",
    "\n",
    "request_token = 'your_request_token'\n",
    "session = kite.generate_session(request_token, api_secret)\n",
    "access_token = session['access_token']\n",
    "kite.set_access_token(access_token)\n",
    "\n",
    "instruments = pd.DataFrame(kite.instruments('NSE'))\n",
    "\n",
    "\n",
    "def lookup(df, symbol):\n",
    "    try:\n",
    "        return df[df.tradingsymbol==symbol].instrument_token.values[0]\n",
    "    except:\n",
    "        return -1\n",
    "\n",
    "def fetchandstoreOHLC(symbol,duration,tf):\n",
    "    nodata=[]\n",
    "    try:\n",
    "        if not os.path.isfile(symbol+'.csv'):\n",
    "            data = pd.DataFrame()\n",
    "            instrument_token = lookup(instruments, symbol)  \n",
    "            if duration>100:\n",
    "                no_of_hundreds = duration//100\n",
    "                start = 100\n",
    "                end = 0\n",
    "                for i in range(no_of_hundreds):\n",
    "                    df = pd.DataFrame(kite.historical_data(instrument_token, from_date = dt.datetime.today()-dt.timedelta(start), \n",
    "                    to_date = dt.datetime.today()-dt.timedelta(end), interval = tf))\n",
    "                    data = data.append(df)\n",
    "                    start+=100\n",
    "                    end+=100\n",
    "                dur1 = duration%100\n",
    "                df1 = pd.DataFrame(kite.historical_data(instrument_token, from_date = dt.datetime.today()-dt.timedelta(duration), \n",
    "                                      to_date = dt.datetime.today()-dt.timedelta(duration-dur1), interval = tf))\n",
    "                data = data.append(df1)\n",
    "            else:\n",
    "                df2 = pd.DataFrame(kite.historical_data(instrument_token, from_date = dt.datetime.today()-dt.timedelta(duration), \n",
    "                                      to_date = dt.datetime.today(), interval = tf))\n",
    "                data = data.append(df2)\n",
    "            data.set_index(\"date\", inplace = True)\n",
    "            data.sort_index(ascending= True,inplace = True)\n",
    "            print('Storing {} days data for {}'.format(duration, symbol))\n",
    "            data.to_csv(symbol+'.csv')\n",
    "        else:\n",
    "            print('Data already available for{}'.format(symbol))\n",
    "            return\n",
    "    except:\n",
    "        print(\"skipping for {}\".format(symbol))\n",
    "        nodata.append(symbol)\n",
    "    \n",
    "tickers = ['HDFCBANK','ICICIBANK','KOTAKBANK', 'AXISBANK', 'SBIN', 'RELIANCE','TCS','INFY','HINDUNILVR','HDFC','BAJFINANCE','WIPRO','BHARTIARTL','HCLTECH','ASIANPAINT','ITC','LT','ULTRACEMCO',\n",
    "           'MARUTI','SUNPHARMA','TATASTEEL','JSWSTEEL','TITAN','ADANIPORTS','ONGC','HDFCLIFE','TECHM','DIVISLAB','POWERGRID','SBILIFE','NTPC','BAJAJ-AUTO','BPCL','IOC','M&M','SHREECEM','HINDALCO',\n",
    "           'GRASIM','BRITANNIA','TATAMOTORS','COALINDIA','TATACONSUM','INDUSINDBK','DRREDDY','CIPLA','EICHERMOT','UPL','NESTLEIND','HEROMOTOCO','NIFTY 50','NIFTY BANK']\n",
    "\n",
    "\n",
    "for ticker in tickers:\n",
    "    fetchandstoreOHLC(ticker, 1095, '5minute')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Angel One:\n",
    "SMARTAPI-PYTHON is a Python library for dealing AMX,that is a set of REST-like HTTP APIs that expose many capabilities required to build stock market investment and trading platforms. It lets you execute orders in real time.\n",
    "When a request is successfully placed the candle data for that time period is returned. The possible interval values can be referred from below table. API is as below\n",
    "\n",
    "https://apiconnect.angelbroking.com/rest/secure/angelbroking/historical/v1/getCandleData\n",
    "#### Exchange Constants\n",
    "Param\tValue\tDescription\n",
    "exchange\tNSE\tNSE Equity\n",
    "NFO\tOnly available for NSE Futures\n",
    "#### Interval Constants\n",
    "|Interval|\tDescription|\n",
    "|---|---|\n",
    "|ONE_MINUTE\t|1 Minute|\n",
    "|THREE_MINUTE |3 Minute|\n",
    "|FIVE_MINUTE\t|5 Minute|\n",
    "|TEN_MINUTE\t|10 Minute|\n",
    "|FIFTEEN_MINUTE|15 Minute|\n",
    "|THIRTY_MINUTE\t|30 Minute|\n",
    "|ONE_HOUR\t|1 Hour|\n",
    "|ONE_DAY\t|1 Day|\n",
    "#### Max Days in one Request\n",
    "|Interval\t|Max Days in one Request|\n",
    "|---|---|\n",
    "|ONE_MINUTE|\t30|\n",
    "|THREE_MINUTE|\t90|\n",
    "|FIVE_MINUTE\t|90|\n",
    "|TEN_MINUTE\t|90|\n",
    "|FIFTEEN_MINUTE|\t180|\n",
    "|THIRTY_MINUTE\t|180|\n",
    "|ONE_HOUR\t|365|\n",
    "|ONE_DAY\t|2000|\n",
    "### Get Candle Data\n",
    "All requests and its response structure is as below.  \n",
    "Get Candle Data Request  \n",
    "{  \n",
    "     \"exchange\": \"NSE\",  \n",
    "     \"symboltoken\": \"3045\",  \n",
    "     \"interval\": \"ONE_MINUTE\",  \n",
    "     \"fromdate\": \"2021-02-10 09:15\",  \n",
    "     \"todate\": \"2021-02-10 09:16\"  \n",
    "}  \n",
    "#### Get Candle Data Response  \n",
    "{  \n",
    "     \"status\": true,  \n",
    "     \"message\": \"SUCCESS\",  \n",
    "     \"errorcode\": \"\",  \n",
    "     \"data\": [  \n",
    "          [  \n",
    "               \"2021-02-10T09:15:00+05:30\",  \n",
    "               394.05,  \n",
    "               397.7,  \n",
    "               394,  \n",
    "               396.3,  \n",
    "               722616  \n",
    "          ],  \n",
    "          [  \n",
    "               \"2021-02-10T09:16:00+05:30\",  \n",
    "               396.25,  \n",
    "               396.65,  \n",
    "               395.85,  \n",
    "               395.85,  \n",
    "               391702  \n",
    "          ]  \n",
    "     ]  \n",
    "}  \n",
    "  \n",
    "NOTE:  \n",
    "Historical API only available for NSE Equity(NSE) and NSE Futures (NFO) Segment  \n",
    "In Get Candle Data Request fromdate and todate format should be \"yyyy-MM-dd hh:mm\"  \n",
    "The response is an array of records, where each record in turn is an array of the following values — [timestamp, open, high, low, close, volume].  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pip install websocket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smartapi.smartConnect import SmartConnect\n",
    "import pandas as pd\n",
    "import requests\n",
    "feed_token = None\n",
    "token_map = None\n",
    "\n",
    "obj = SmartConnect(api_key=\"LreBghDE\")\n",
    "data = obj.generateSession(\"123456\", \"Tannu@123\")\n",
    "print(data)\n",
    "refreshToken=data['data']['refreshToken']\n",
    "\n",
    "#fetch the feedtoken\n",
    "feedToken = obj.getfeedToken()\n",
    "feed_token = feedToken\n",
    "#fetch User Profile\n",
    "userProfile = obj.getProfile((refreshToken))\n",
    "print(userProfile)\n",
    "\n",
    "#historic api\n",
    "def OHLCHistory(symbol, token, interval, fdate, todate):\n",
    "    try:\n",
    "        historicParam={\n",
    "            \"exchange\":\"NSE\",\n",
    "            \"tradingsymbol\":symbol,\n",
    "            \"symboltoken\":token,\n",
    "            \"interval\":interval,\n",
    "            \"fromdate\":fdate,\n",
    "            \"todate\":todate\n",
    "        }\n",
    "        history = obj.getCandleData(historicParam)['data']\n",
    "        history = pd.DataFrame(history)\n",
    "\n",
    "        history = history.rename(\n",
    "            columns={0: \"DateTime\", 1: \"open\", 2: \"high\", 3: \"low\", 4: \"close\", 5:\"Volumne\"}\n",
    "        )\n",
    "        history['DateTime']=pd.to_datetime(history['DataTime'])\n",
    "        history=history.set_index('DateTime')\n",
    "        return history\n",
    "    except Exception as e:\n",
    "        print(\"Histpric api failed: {}\".format(e))\n",
    "data = OHLCHistory(\"SBIN-EQ\", \"3045\", \"ONE_DAY\", \"2020-02-08 00:00\", \"2021-02-08 15:30\")\n",
    "data_df = pd.DataFrame(data)\n",
    "data_df.to_csv(r'{}.csv'.format(\"SBIN_EQ\"), index=True, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polygio.io\n",
    "\n",
    "## Parameters\n",
    "stocksTicker\n",
    "*\n",
    "AAPL\n",
    "The ticker symbol of the stock/equity.\n",
    "\n",
    "multiplier\n",
    "*\n",
    "1\n",
    "The size of the timespan multiplier.\n",
    "\n",
    "timespan\n",
    "*\n",
    "\n",
    "day\n",
    "The size of the time window.\n",
    "\n",
    "from\n",
    "*\n",
    "2021-07-22\n",
    "The start of the aggregate time window. Either a date with the format YYYY-MM-DD or a millisecond timestamp.\n",
    "\n",
    "to\n",
    "*\n",
    "2021-07-22\n",
    "The end of the aggregate time window. Either a date with the format YYYY-MM-DD or a millisecond timestamp.\n",
    "\n",
    "adjusted\n",
    "\n",
    "Whether or not the results are adjusted for splits. By default, results are adjusted. Set this to false to get results that are NOT adjusted for splits.\n",
    "\n",
    "sort\n",
    "\n",
    "asc\n",
    "Sort the results by timestamp. asc will return results in ascending order (oldest at the top), desc will return results in descending order (newest at the top).\n",
    "\n",
    "limit\n",
    "120\n",
    "Limits the number of base aggregates queried to create the aggregate results. Max 50000 and Default 5000. Read more about how limit is used to calculate aggregate results in our article on Aggregate Data API Improvements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install polygon-api-client\n",
    "pip install local_settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlite3 import adapters\n",
    "from polygon import RESTClient\n",
    "from local_settings import polygon as settings\n",
    "from requests.adapters import HTTPAdapter\n",
    "from urllib3.util.retry import Retry\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "markets = ['crypto', 'stocks']\n",
    "\n",
    "class MyRESTClient(RESTClient):\n",
    "    def __init__(self, auth_key: str, timeout: int=None):\n",
    "        super().__init__(auth_key)\n",
    "        retry_strategy = Retry(total=10, backoff_factor=10, status_forcelist=[429, 500, 503, 504])\n",
    "        adapter = HTTPAdapter(max_retries=retry_strategy)\n",
    "        self._session.mount('https://', adapter)\n",
    "    \n",
    "    def get_bars(self, market:str=None, ticker:str=None, multiplier:int=1, timespan:str='minute', from_:date=None, to:date=None) -> pd.DataFrame:\n",
    "        if not market in markets:\n",
    "            raise Exception(f'Market must be one of {markets}.')\n",
    "        \n",
    "        if ticker is None:\n",
    "            raise Exception('Ticker must not be None.')\n",
    "        \n",
    "        from_ = from_ if from_ else data(2000, 1, 1)\n",
    "        to = to if to else date.today()\n",
    "\n",
    "        if market == 'stocks':\n",
    "            resp = self.stocks_aggregates(ticker, multiplier, timespan, from_.strftime('%Y-%m-%d'), to..strftime('%Y-%m-%d'), limit=50000)\n",
    "            df = pd.DataFrame(resp.results)\n",
    "            last_minute = 0\n",
    "            while resp.results[-1]['t'] > last_minute:\n",
    "                last_minute = resp.results[-1]['t']\n",
    "                last_minute_date = datetime.fromtimestamp(last_minute/1000).strftime('%Y-%m-%d')\n",
    "                resp = self.stocks_aggregates(ticker, multiplier, timespan, from_.strftime('%Y-%m-%d'), to..strftime('%Y-%m-%d'), limit=50000)\n",
    "                new_bars = pd.DataFrame(resp.results)\n",
    "                df = df.append(new_bars[new_bars['t']>last_minute])\n",
    "\n",
    "            df['date'] = pd.to_datetime(df['t'], unit='ms')\n",
    "            df = df.rename(columns={\n",
    "                'o':'open',\n",
    "                'h':'high',\n",
    "                'l':\"low\",\n",
    "                'c':'close',\n",
    "                'v':'volume',\n",
    "                'vw':'vwap',\n",
    "                'n':'transactions'})\n",
    "            \n",
    "            df = df[['date', 'open', 'high', 'low' ,'close', 'volume']]\n",
    "            return df\n",
    "    return None\n",
    "\n",
    "\n",
    "client = MyRESTClient(settings['api_key'])\n",
    "ticker='AAPL'\n",
    "df = client.get_bars(market=\"stocks\", ticker=ticker)\n",
    "df.to_csv(r'{}.csv'.format(ticker), header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kotak Securities\n",
    "\n",
    "All URIs are relative to https://tradeapi.kotaksecurities.com/apim\n",
    "\n",
    "|Class|\tMethod|\tDescription|\n",
    "|---|---|---|\n",
    "|SessionApi\t|ks_api.KSTradeApi\t|Initialise Session\n",
    "|SessionApi\t|login\t|Login using Userid\n",
    "|SessionApi\t|session_2fa|\tGenerate final Session Token\n",
    "|OrderApi\t|place_order|\tPlace a New order\n",
    "|OrderApi\t|modify_order|\tModify an existing order\n",
    "|OrderApi\t|cancel_order|\tCancel an order\n",
    "|ReportsApi\t|order_report|\tGet order report\n",
    "|ReportsApi\t|trade_report|\tGet trade report\n",
    "|MarginApi\t|margin_required|\tGet Margin Required for an order by amount or quantity.\n",
    "|PositionsApi\t|positions\t|Get's Open position.\n",
    "|QuoteApi\t|quote\t|Get Quote details\n",
    "|HistoricalApi|\thistory|\tGet historical data.\n",
    "|SessionApi\t|logout\t|Invalidate Session Token\n",
    "\n",
    "#### get_resource\n",
    "object history(resource, input)  \n",
    "Get historical data based on given resource  \n",
    "Get Historical data  \n",
    "\n",
    "#### Parameters\n",
    "|Name|\tType|\tDescription\tNotes|\n",
    "|---|---|---|\n",
    "|resource|\tstr\t|\tType of resource historicalprices,historicalprices-unadjusted,NSEFNO_HistoricalContinuousChart,LiveorEODHistorical|\n",
    "|input\t|str\t|\tJson as per resource selected|\n",
    "\n",
    "#### Return type\n",
    "object\n",
    "\n",
    "#### HTTP request headers\n",
    "Accept: application/json\n",
    "\n",
    "#### HTTP response details\n",
    "|Status code\t|Description|\n",
    "|---|---|\n",
    "|200|\tHistorical Details|\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install git+https://github.com/osparamatrix/ks-orderapi-python.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ks_api_client import ks_api\n",
    "\n",
    "client = ks_api.KSTradeApi(access_token = \"access_token\", userid = \"userid\", \\\n",
    "                 consumer_key = \"consumer_key\", ip = \"IP\", app_id = \"app_id\")\n",
    "\n",
    "#First initialize session and generate session token\n",
    "\n",
    "try:\n",
    "    # Get historical prices\n",
    "    client.history(\"historicalprices\",{\"exchange\":\"bse\",\"cocode\":\"476\",\"fromdate\":\"01-jan-2014\",\"todate\":\"08-oct-2015\"})\n",
    "except Exception as e:\n",
    "    print(\"Exception when calling Historical API->details: %s\\n\" % e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ALice Blue API\n",
    "\n",
    "Alice Blue Python library provides an easy to use wrapper over the HTTPS APIs.  \n",
    "The HTTP calls have been converted to methods and JSON responses are wrapped into Python-compatible objects.  \n",
    "Websocket connections are handled automatically within the library.  \n",
    "\n",
    "#### Installation\n",
    "To force upgrade existing installations:  \n",
    "\n",
    "pip uninstall alice_blue  \n",
    "pip --no-cache-dir install --upgrade alice_blue  \n",
    "\n",
    "#### Getting Started with API\n",
    "\n",
    "There is only one class in the whole library: AliceBlue. The login_and_get_sessioID() static method is used to retrieve session ID from alice blue server. A session ID is valid for 24 hours. With session ID, you can instantiate an AliceBlue object. Ideally you only need to create a session ID once every day. Once the session ID is created new, it'll be stored in a temporary location. Next time, the same session ID will be used.  \n",
    "\n",
    "#### Logging\n",
    "The whole library is equipped with python's logging module for debugging. If more debug information is needed, enable logging using the following code.  \n",
    "import logging  \n",
    "logging.basicConfig(level=logging.DEBUG)  \n",
    "\n",
    "#### Getting an session ID\n",
    "1. Import alice_blue  \n",
    "2. Create session_id using login_and_get_sessioID() function with your username, password, 2FA (2fa is now year of birth), app_id and api_secret.  \n",
    "\n",
    "#### Problem getting access token\n",
    "If you are facing problem getting access token, make sure the following are correct.  \n",
    "username.  \n",
    "password.  \n",
    "2FA.  \n",
    "api secret.  \n",
    "app id.  \n",
    "Even after verifying all these, if you are facing problem, contact alice customer care. They should enable the API access in their end.  \n",
    "\n",
    "#### Historical API\n",
    "Alice Blue now supports downloading historical data for back testing.  \n",
    "  \n",
    "1. Historical data API will be available from 5:30 PM (evening) to 8 AM (Next day morning) on weekdays (Monday to Friday). Historical data will not be available during market hours.  \n",
    "2. Historical data API will be available fully during weekends and holidays.  \n",
    "3. For NSE segment, 2 years of historical data will be provided.  \n",
    "4. For NFO, CDS and MCX segments, current expiry data will be provided.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip --no-cache-dir install --upgrade alice_blue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from alice_blue import *\n",
    "session_id = AliceBlue.login_and_get_sessioID(username = \"username\", password = \"password\", twoFA= \"1993\", app_id = \"app_id\", api_secret = \"api_secret\")\n",
    "data = pd.DataFrame(alice.historical_data(alice.get_instrument_by_symbol(\"NSE\"), datetime.datetime.now(), datetime.datetime.now(), HistoricalDataType.Minute))\n",
    "data.to_csv(\"NSE.csv\", header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8f8cf99212f81ad0c4765861267244807ee1c18364846cdce387b28994a977ba"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
