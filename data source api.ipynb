{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Historical Data: Intraday"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These financial data are generally provided in a format that includes the following information:  \n",
    "Date  \n",
    "Open Price  \n",
    "High Price  \n",
    "Low Price  \n",
    "Closing Price  \n",
    "Volume\n",
    "These data—often referred to as OHLC Chart Data—can be interpreted as Time Series data and are perfect for performing technical analysis. We’ll dive into this format in just a moment but, for now, just realize this is a standard format for historical pricing data within financial markets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [yfinance]()\n",
    "\n",
    "For this approach, we need to install the yfinance library as `pip install yfinance`. This library provides sample tools for working with financial data requests to the Yahoo Finance website.  \n",
    "> ⚠️ periodic breakage, general quirkiness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "tick = ['NVDA']\n",
    "#for i in tick:\n",
    "data = yf.download('NVDA', period='max', auto_adjust=True)\n",
    "print(data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install yahoofinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yahoofinance import HistoricalPrices\n",
    "req = HistoricalPrices('AAPL', '1999-01-22', '2022-09-15')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quandl:\n",
    "Quandl offers official APIs to access any public dataset for free. One important note is that the **free Quandl OHLC data only goes up to 2018**.  \n",
    "\n",
    " ⚠️ Providing Only US market Data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import quandl\n",
    "#import time\n",
    "#tick = ['NVDA','MSFT','AAC','AACG', 'AACI','AACIW','AADI','AAIC','AAL','AAMC','AAME','AAN','AAOI','AAON','AAP','AAPL','AAQC','AAT','AATC','AAU','AAWW','AB','ABB','ABBV','ABC']\n",
    "# Get data via Quandl API\n",
    "#data = quandl.get('WIKI/NVDA')\n",
    "#data.info()\n",
    "msft = quandl.get('WIKI/MSFT', start_date='1986-03-13', end_date='15-09-2022')\n",
    "msft.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alpha Vantage:\n",
    " ✌️ Providing Free 20 years of data with no missing values.  \n",
    " ⚠️ period breakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# replace the \"demo\" apikey below with your own key from https://www.alphavantage.co/support/#api-key\n",
    "url = 'https://www.alphavantage.co/query?function=TIME_SERIES_DAILY&symbol=IBM&outputsize=full&apikey=UNO4CZQHSBZSN71N'\n",
    "r = requests.get(url)\n",
    "data= r.json()\n",
    "timeseries = data['Time Series (Daily)']\n",
    "value2 = dict()\n",
    "extra = list()\n",
    "index = ['open', 'high', 'low', 'close', 'volume']\n",
    "for value in timeseries:\n",
    "    for key in timeseries.get(value):\n",
    "        extra.append(timeseries[value][key])\n",
    "    value2[value]=extra\n",
    "    extra = list()\n",
    "\n",
    "    \n",
    "df = pd.DataFrame(value2, index=index).T\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zerodha-historical-data-download :\n",
    "This contains code to download historical data for more than 2000 days and intraday data for more than 100 days.  \n",
    "⚠️ Not provinding free historical data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kiteconnect import KiteConnect, KiteTicker\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "\n",
    "\n",
    "\n",
    "api_key = 'your_api_key'\n",
    "api_secret = 'your_api_secret'\n",
    "\n",
    "kite = KiteConnect(api_key)\n",
    "url = kite.login_url()\n",
    "\n",
    "request_token = 'your_request_token'\n",
    "session = kite.generate_session(request_token, api_secret)\n",
    "access_token = session['access_token']\n",
    "kite.set_access_token(access_token)\n",
    "\n",
    "instruments = pd.DataFrame(kite.instruments('NSE'))\n",
    "\n",
    "\n",
    "def lookup(df, symbol):\n",
    "    try:\n",
    "        return df[df.tradingsymbol==symbol].instrument_token.values[0]\n",
    "    except:\n",
    "        return -1\n",
    "\n",
    "def fetchandstoreOHLC(symbol,duration,tf):\n",
    "    nodata=[]\n",
    "    try:\n",
    "        if not os.path.isfile(symbol+'.csv'):\n",
    "            data = pd.DataFrame()\n",
    "            instrument_token = lookup(instruments, symbol)  \n",
    "            if duration>100:\n",
    "                no_of_hundreds = duration//100\n",
    "                start = 100\n",
    "                end = 0\n",
    "                for i in range(no_of_hundreds):\n",
    "                    df = pd.DataFrame(kite.historical_data(instrument_token, from_date = dt.datetime.today()-dt.timedelta(start), \n",
    "                    to_date = dt.datetime.today()-dt.timedelta(end), interval = tf))\n",
    "                    data = data.append(df)\n",
    "                    start+=100\n",
    "                    end+=100\n",
    "                dur1 = duration%100\n",
    "                df1 = pd.DataFrame(kite.historical_data(instrument_token, from_date = dt.datetime.today()-dt.timedelta(duration), \n",
    "                                      to_date = dt.datetime.today()-dt.timedelta(duration-dur1), interval = tf))\n",
    "                data = data.append(df1)\n",
    "            else:\n",
    "                df2 = pd.DataFrame(kite.historical_data(instrument_token, from_date = dt.datetime.today()-dt.timedelta(duration), \n",
    "                                      to_date = dt.datetime.today(), interval = tf))\n",
    "                data = data.append(df2)\n",
    "            data.set_index(\"date\", inplace = True)\n",
    "            data.sort_index(ascending= True,inplace = True)\n",
    "            print('Storing {} days data for {}'.format(duration, symbol))\n",
    "            data.to_csv(symbol+'.csv')\n",
    "        else:\n",
    "            print('Data already available for{}'.format(symbol))\n",
    "            return\n",
    "    except:\n",
    "        print(\"skipping for {}\".format(symbol))\n",
    "        nodata.append(symbol)\n",
    "    \n",
    "tickers = ['HDFCBANK','ICICIBANK','KOTAKBANK', 'AXISBANK', 'SBIN', 'RELIANCE','TCS','INFY','HINDUNILVR','HDFC','BAJFINANCE','WIPRO','BHARTIARTL','HCLTECH','ASIANPAINT','ITC','LT','ULTRACEMCO',\n",
    "           'MARUTI','SUNPHARMA','TATASTEEL','JSWSTEEL','TITAN','ADANIPORTS','ONGC','HDFCLIFE','TECHM','DIVISLAB','POWERGRID','SBILIFE','NTPC','BAJAJ-AUTO','BPCL','IOC','M&M','SHREECEM','HINDALCO',\n",
    "           'GRASIM','BRITANNIA','TATAMOTORS','COALINDIA','TATACONSUM','INDUSINDBK','DRREDDY','CIPLA','EICHERMOT','UPL','NESTLEIND','HEROMOTOCO','NIFTY 50','NIFTY BANK']\n",
    "\n",
    "\n",
    "for ticker in tickers:\n",
    "    fetchandstoreOHLC(ticker, 1095, '5minute')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Angel One]():\n",
    "SMARTAPI-PYTHON is a Python library for dealing AMX,that is a set of REST-like HTTP APIs that expose many capabilities required to build stock market investment and trading platform.\n",
    "API is as below:  \n",
    "https://apiconnect.angelbroking.com/rest/secure/angelbroking/historical/v1/getCandleData\n",
    " \n",
    "> NOTE:  Historical API only available for NSE Equity(NSE) and NSE Futures (NFO) Segment  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smartapi.smartConnect import SmartConnect\n",
    "import pandas as pd\n",
    "import requests\n",
    "feed_token = None\n",
    "token_map = None\n",
    "\n",
    "obj = SmartConnect(api_key=\"TkDi9GY2\")\n",
    "data = obj.generateSession(\"R12345\", \"Tannu@123\")\n",
    "print(data)\n",
    "refreshToken=data['data']['refreshToken']\n",
    "\n",
    "#fetch the feedtoken\n",
    "feedToken = obj.getfeedToken()\n",
    "feed_token = feedToken\n",
    "#fetch User Profile\n",
    "userProfile = obj.getProfile((refreshToken))\n",
    "print(userProfile)\n",
    "\n",
    "#historic api\n",
    "def OHLCHistory(symbol, token, interval, fdate, todate):\n",
    "    try:\n",
    "        historicParam={\n",
    "            \"exchange\":\"NSE\",\n",
    "            \"tradingsymbol\":symbol,\n",
    "            \"symboltoken\":token,\n",
    "            \"interval\":interval,\n",
    "            \"fromdate\":fdate,\n",
    "            \"todate\":todate\n",
    "        }\n",
    "        history = obj.getCandleData(historicParam)['data']\n",
    "        history = pd.DataFrame(history)\n",
    "\n",
    "        history = history.rename(\n",
    "            columns={0: \"DateTime\", 1: \"open\", 2: \"high\", 3: \"low\", 4: \"close\", 5:\"Volumne\"}\n",
    "        )\n",
    "        history['DateTime']=pd.to_datetime(history['DataTime'])\n",
    "        history=history.set_index('DateTime')\n",
    "        return history\n",
    "    except Exception as e:\n",
    "        print(\"Histpric api failed: {}\".format(e))\n",
    "data = OHLCHistory(\"SBIN-EQ\", \"3045\", \"ONE_DAY\", \"2020-02-08 00:00\", \"2021-02-08 15:30\")\n",
    "data_df = pd.DataFrame(data)\n",
    "data_df.to_csv(r'{}.csv'.format(\"SBIN_EQ\"), index=True, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Polygio.io]()\n",
    "\n",
    "#### Parameters\n",
    "\n",
    "|Parameter|Default value|Explanation|\n",
    "|---|---|---|\n",
    "|multiplier |1 |The size of the timespan multiplier.|\n",
    "|timespan|day|The size of the time window.|\n",
    "|limit|120|Limits the number of base aggregates queried to create the aggregate results. Max 50000 and Default 5000.|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlite3 import adapters\n",
    "from polygon import RESTClient\n",
    "from local_settings import polygon as settings\n",
    "from requests.adapters import HTTPAdapter\n",
    "from urllib3.util.retry import Retry\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "markets = ['crypto', 'stocks']\n",
    "\n",
    "class MyRESTClient(RESTClient):\n",
    "    def __init__(self, auth_key: str, timeout: int=None):\n",
    "        super().__init__(auth_key)\n",
    "        retry_strategy = Retry(total=10, backoff_factor=10, status_forcelist=[429, 500, 503, 504])\n",
    "        adapter = HTTPAdapter(max_retries=retry_strategy)\n",
    "        self._session.mount('https://', adapter)\n",
    "    \n",
    "    def get_bars(self, market:str=None, ticker:str=None, multiplier:int=1, timespan:str='minute', from_:datetime=None, to:datetime=None) -> pd.DataFrame:\n",
    "        if not market in markets:\n",
    "            raise Exception(f'Market must be one of {markets}.')\n",
    "        \n",
    "        if ticker is None:\n",
    "            raise Exception('Ticker must not be None.')\n",
    "        \n",
    "        from_ = from_ if from_ else data(2000, 1, 1)\n",
    "        to = to if to else date.today()\n",
    "\n",
    "        if market == 'stocks':\n",
    "            resp = self.stocks_aggregates(ticker, multiplier, timespan, from_.strftime('%Y-%m-%d'), to.strftime('%Y-%m-%d'), limit=50000)\n",
    "            df = pd.DataFrame(resp.results)\n",
    "            last_minute = 0\n",
    "            while resp.results[-1]['t'] > last_minute:\n",
    "                last_minute = resp.results[-1]['t']\n",
    "                last_minute_date = datetime.fromtimestamp(last_minute/1000).strftime('%Y-%m-%d')\n",
    "                resp = self.stocks_aggregates(ticker, multiplier, timespan, from_.strftime('%Y-%m-%d'), to.strftime('%Y-%m-%d'), limit=50000)\n",
    "                new_bars = pd.DataFrame(resp.results)\n",
    "                df = df.append(new_bars[new_bars['t']>last_minute])\n",
    "\n",
    "            df['date'] = pd.to_datetime(df['t'], unit='ms')\n",
    "            df = df.rename(columns={\n",
    "                'o':'open',\n",
    "                'h':'high',\n",
    "                'l':\"low\",\n",
    "                'c':'close',\n",
    "                'v':'volume',\n",
    "                'vw':'vwap',\n",
    "                'n':'transactions'})\n",
    "            \n",
    "            df = df[['date', 'open', 'high', 'low' ,'close', 'volume']]\n",
    "            return df\n",
    "        return None\n",
    "\n",
    "\n",
    "client = MyRESTClient(polygon['api_key'])\n",
    "ticker='AAPL'\n",
    "df = client.get_bars(market=\"stocks\", ticker=ticker)\n",
    "df.to_csv(r'{}.csv'.format(ticker))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Kotak Securities]()\n",
    "\n",
    "All URIs are relative to https://tradeapi.kotaksecurities.com/apim\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ks_api_client import ks_api\n",
    "\n",
    "client = ks_api.KSTradeApi(access_token = \"access_token\", userid = \"userid\", \\\n",
    "                 consumer_key = \"consumer_key\", ip = \"IP\", app_id = \"app_id\")\n",
    "\n",
    "#First initialize session and generate session token\n",
    "\n",
    "try:\n",
    "    # Get historical prices\n",
    "    client.history(\"historicalprices\",{\"exchange\":\"bse\",\"cocode\":\"476\",\"fromdate\":\"01-jan-2014\",\"todate\":\"08-oct-2015\"})\n",
    "except Exception as e:\n",
    "    print(\"Exception when calling Historical API->details: %s\\n\" % e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [ALice Blue API]()\n",
    "\n",
    "1. Historical data API will be available from 5:30 PM (evening) to 8 AM (Next day morning) on weekdays (Monday to Friday). Historical data will not be available during market hours.  \n",
    "2. Historical data API will be available fully during weekends and holidays.  \n",
    "3. For NSE segment, 2 years of historical data will be provided.  \n",
    "4. For NFO, CDS and MCX segments, current expiry data will be provided.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from alice_blue import *\n",
    "session_id = AliceBlue.login_and_get_sessioID(username = \"username\", password = \"password\", twoFA= \"1993\", app_id = \"app_id\", api_secret = \"api_secret\")\n",
    "data = pd.DataFrame(alice.historical_data(alice.get_instrument_by_symbol(\"NSE\"), datetime.datetime.now(), datetime.datetime.now(), HistoricalDataType.Minute))\n",
    "data.to_csv(\"NSE.csv\", header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8f8cf99212f81ad0c4765861267244807ee1c18364846cdce387b28994a977ba"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
